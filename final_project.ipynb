{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.color import rgb2lab, lab2rgb\n",
    "\n",
    "# scale to 256 * 256 then perform random crop to 224 * 224\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# scale to 224 * 224\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class ColorizationDataset(datasets.ImageFolder):\n",
    "    '''\n",
    "    Custom Dataset for colorization\n",
    "    '''\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample, target = super(ColorizationDataset, self).__getitem__(index)\n",
    "        # color range L: [0,100], a&b: [-128, 127]\n",
    "        lab = rgb2lab(sample.permute(1, 2, 0))\n",
    "        l = lab[:, :, 0:1]\n",
    "        # normalize a&b to [0, 1]\n",
    "        ab = (lab[:, :, 1:] + 128) / 255\n",
    "        return l, ab, target\n",
    "\n",
    "data_root = '/Users/yuli/Downloads/places365_standard'\n",
    "train_dir = os.path.join(data_root, 'train')\n",
    "train_set = ColorizationDataset(train_dir, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dir = os.path.join(data_root, 'val')\n",
    "val_set = ColorizationDataset(val_dir, transform=transform_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "    \n",
    "dataiter = iter(train_loader)\n",
    "lchannels, abchannels, labels = dataiter.next()\n",
    "\n",
    "\n",
    "def classificationLoss(outputs, labels):\n",
    "    '''\n",
    "    Calculate the cross-entropy loss for the classification network.\n",
    "    The classification loss affects the low-level features network,\n",
    "    global features network, and the classification network.\n",
    "    '''\n",
    "    return nn.CrossEntropyLoss()(outputs, labels)\n",
    "\n",
    "\n",
    "def colorizationLoss(coloroutputs, colorlabels, classoutputs, classlabels):\n",
    "    '''\n",
    "    Calculate the loss for the colorization network.\n",
    "    The colorization loss affects the entire network.\n",
    "    '''\n",
    "    # Choose an alpha so that the MSE loss and the cross-entropy loss\n",
    "    # are similar in magnitude.\n",
    "    alpha = 1.0 / 300 \n",
    "    # Calculate the MSE loss for the colorization network\n",
    "    colorLoss = nn.MSELoss()(coloroutputs, colorlabels)\n",
    "    # Calculate the classification loss\n",
    "    classLoss = classificationLoss(classoutputs, classlabels)\n",
    "    return colorLoss - alpha * classLoss\n",
    "\n",
    "\n",
    "def train(train_loader, color_model, class_model, color_optimizer, class_optimizer):\n",
    "    '''\n",
    "    Train both colorization and classification models. \n",
    "    '''\n",
    "    color_model.train()\n",
    "    class_model.train()\n",
    "    count = 0\n",
    "    loss_sum = 0.0\n",
    "    for i, (inputs, colors, labels) in enumerate(train_loader):\n",
    "        # predict and compute loss\n",
    "        color_preds = color_model(inputs)\n",
    "        label_preds = class_model(inputs)\n",
    "        loss = colorizationLoss(color_preds, colors, label_preds, labels)\n",
    "        \n",
    "        # record loss\n",
    "        loss_sum += loss.item()\n",
    "        count += inputs.size(0)\n",
    "        \n",
    "        # compute gradient and do Adadelta step for both colorization and classification networks.\n",
    "        color_optimizer.zero_grad()\n",
    "        class_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        color_optimizer.step()\n",
    "        class_optimizer.step()\n",
    "    \n",
    "    return loss_sum / count\n",
    "        \n",
    "def validate(val_loader, color_model, class_model):\n",
    "    '''\n",
    "    Evaluate both colorization and classification models.\n",
    "    '''\n",
    "    color_model.eval()\n",
    "    class_model.eval()\n",
    "    count = 0\n",
    "    loss_sum = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, colors, labels) in enumerate(val_loader):\n",
    "            # predict and compute losses\n",
    "            color_preds = color_model(inputs)\n",
    "            label_preds = class_model(inputs)\n",
    "            loss = colorizationLoss(color_preds, colors, label_preds, labels)\n",
    "            \n",
    "            # record loss\n",
    "            loss_sum += loss.item()\n",
    "            count += inputs.size(0)\n",
    "    \n",
    "    return loss_sum / count\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    '''\n",
    "    Save checkpoint for the given state. \n",
    "    '''\n",
    "    torch.save(state, filename)\n",
    "\n",
    "def load_checkpoint(filename='checkpoint.pth.tar'):\n",
    "    '''\n",
    "    Load checkpoint from file. \n",
    "    '''\n",
    "    if os.path.isfile(filename):\n",
    "        return torch.load(filename)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Initialize models and optimizers\n",
    "# color_model = \n",
    "# class_model =\n",
    "color_optimizer = optim.Adadelta(color_model.parameters(), lr=1)\n",
    "class_optimizer = optim.Adadelta(class_model.parameters(), lr=1)\n",
    "start_epoch = 0\n",
    "total_epochs = 10\n",
    "best_loss = float(\"inf\")\n",
    "losses = []\n",
    "# Load from checkpoint if exists\n",
    "checkpoint = load_checkpoint()\n",
    "if checkpoint:\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "    color_model.load_state_dict(checkpoint['color_state_dict'])\n",
    "    class_model.load_state_dict(checkpoint['class_state_dict'])\n",
    "    color_optimizer.load_state_dict(checkpoint['color_optimizer'])\n",
    "    class_optimizer.load_state_dict(checkpoint['class_optimizer'])\n",
    "for epoch in range(start_epoch, total_epochs):\n",
    "    if args.distributed:\n",
    "        train_sampler.set_epoch(epoch)\n",
    "    # train for one epoch\n",
    "    train_loss = train(train_loader, color_model, class_model, color_optimizer, class_optimizer)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    val_loss = validate(val_loader, color_model, class_model)\n",
    "    losses.append(val_loss)\n",
    "    new_checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'losses': losses\n",
    "        'color_state_dict': color_model.state_dict(),\n",
    "        'class_state_dict': class_model.state_dict(),\n",
    "        'color_optimizer' : color_optimizer.state_dict(),\n",
    "        'class_optimizer' : class_optimizer.state_dict()\n",
    "    }\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        # save the best checkpoint\n",
    "        save_checkpoint(new_checkpoint, 'best_checkpoint.pth.tar')\n",
    "    # save checkpoint\n",
    "    save_checkpoint(new_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
